function [W]= LearningLSF(train_data, test_data, train_target, test_target)
%% LLSF Optimization Parameters(Parameters set to LLSF optimal parameters)
optmParameter.alpha   = 2^8;  % 2.^[-10:10] % label correlation
optmParameter.beta    = 2^8; % 2.^[-10:10] % sparsity
optmParameter.gamma   = 1; % {0.1, 1, 10} % initialization for W

optmParameter.searchPara = 0; % indicate whether tuning the parameters, {0:not,1:yes}
optmParameter.tuneParaOneTime = 1; % indicate that tuning the parameter one time or tuning it in each fold. {0: each fold,1: only one time}

% for large scale dataset, search ranges for alpha and beta should be set to large values,
% e.g., 4.^[-10:10];
optmParameter.alpha_searchrange = 2.^[-10:10]; 
optmParameter.beta_searchrange  = 2.^[-10:10];
optmParameter.gamma_searchrange = 10.^[-1:1];
    
optmParameter.maxIter           = 100;
optmParameter.minimumLossMargin = 0.0001;
optmParameter.bQuiet             = 1;

%% Model Parameters
modelparameter.crossvalidation    = 1; % {0,1}
modelparameter.cv_num             = 5;
modelparameter.L2Norm             = 1; % {0,1}
modelparameter.drawNumofFeatures  = 0; % {0,1}
modelparameter.deleteData         = 1; % {0,1}

%% Train and Test
if modelparameter.crossvalidation==0 
else
%% cross validation
    if exist('train_data','var')==1
        data=[train_data;test_data];
        target=[train_target,test_target];
        clear train_data test_data train_target test_target
    end
    data     = double(data);
    num_data = size(data,1);
    if modelparameter.L2Norm == 1
        temp_data = data;
        temp_data = temp_data./repmat(sqrt(sum(temp_data.^2,2)),1,size(temp_data,2));
        if sum(sum(isnan(temp_data)))>0
            temp_data = data+eps;
            temp_data = temp_data./repmat(sqrt(sum(temp_data.^2,2)),1,size(temp_data,2));
        end
    else
        temp_data = data;
    end
    if modelparameter.deleteData
        clear data
    end
    
    randorder = randperm(num_data);


    for j = 1:modelparameter.cv_num
        fprintf('Running Fold - %d/%d \n',j,modelparameter.cv_num);

       %% the training and test parts are generated by fixed spliting with the given random order
        [cv_train_data,cv_train_target,cv_test_data,cv_test_target ] = generateCVSet( temp_data,target',randorder,j,modelparameter.cv_num );
        cv_train_target=cv_train_target';
        cv_test_target=cv_test_target';

       %% Tune the parametes
        if optmParameter.searchPara == 1
            if (optmParameter.tuneParaOneTime == 1) && (exist('BestResult','var')==0)
                fprintf('\n-  parameterization for LLSF by cross validation on the training data');
                [optmParameter, BestResult ] = LLSF_adaptive_validate( cv_train_data, cv_train_target, optmParameter);
            elseif (optmParameter.tuneParaOneTime == 0)
                fprintf('\n-  parameterization for LLSF by cross validation on the training data');
                [optmParameter, BestResult ] = LLSF_adaptive_validate( cv_train_data, cv_train_target, optmParameter);
            end
        end
        
       %% If we don't search the parameters, we will run LLSF with the fixed parametrs
        [W]  = LLSF( cv_train_data, cv_train_target',optmParameter);

    end
end
end